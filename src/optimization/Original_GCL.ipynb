{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56fe4aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get the current script's directory\n",
    "current_directory = os.path.dirname(os.path.abspath(__file__)) if \"__file__\" in locals() else os.getcwd()\n",
    "# get the parent directory\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "# add the parent directory to the sys.path\n",
    "sys.path.append(parent_directory)\n",
    "\n",
    "from optimization import functions\n",
    "from optimization.updater import Updater\n",
    "\n",
    "from utils import constants, common\n",
    "from utils.config import Config\n",
    "from utils.dataset_loader import PolicyDatasetLoader\n",
    "\n",
    "from models.policy_model import RobotPolicy\n",
    "from models.reward_model import RewardFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e24f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class AgentVPG(nn.Module):\n",
    "    def __init__(self, state_shape, n_actions):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.state_shape = state_shape\n",
    "        self.n_actions = n_actions\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "          nn.Linear(in_features = state_shape[0], out_features = 128),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(in_features = 128 , out_features = 64),\n",
    "          nn.ReLU())\n",
    "        self.std = \n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.model(x)\n",
    "        return logits\n",
    "    \n",
    "    def predict_probs(self, states):\n",
    "        states = torch.FloatTensor(states)\n",
    "        logits = self.model(states).detach()\n",
    "        \n",
    "        probs = F.softmax(logits, dim = -1).numpy()\n",
    "        \n",
    "        return probs\n",
    "    \n",
    "    def generate_session(self, env, t_max=1000):\n",
    "        states, actions, rewards = [], [], []\n",
    "        s = env.reset()\n",
    "\n",
    "        for t in range(t_max):\n",
    "            action_probs = self.predict_probs(np.array([s]))[0]\n",
    "            a = np.random.choice(self.n_actions,  p = action_probs)\n",
    "            new_s, r, done, info = env.step(a)\n",
    "\n",
    "            states.append(s)\n",
    "            actions.append(a)\n",
    "            rewards.append(r)\n",
    "\n",
    "            s = new_s\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        return states, actions, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4599cbe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ef8a07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
