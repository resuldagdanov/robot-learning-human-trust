{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ac3ab49",
   "metadata": {},
   "source": [
    "# Evaluation Analysis of Developed Methodology for Trust Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702a4771",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddc7efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.colors import Normalize, ListedColormap\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from scipy import stats\n",
    "from typing import Tuple\n",
    "\n",
    "# get the current script's directory\n",
    "current_directory = os.path.dirname(os.path.abspath(__file__)) if \"__file__\" in locals() else os.getcwd()\n",
    "# get the parent directory\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "# add the parent directory to the sys.path at the beginning\n",
    "sys.path.insert(0, parent_directory)\n",
    "\n",
    "from utils import constants, common\n",
    "\n",
    "from optimization import functions\n",
    "\n",
    "from trusts.model_dynamics import TrustDistribution\n",
    "from trusts.mle_optimization import MLEOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a332332",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\",\n",
    "              None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c961a4",
   "metadata": {},
   "source": [
    "## Choose Whether Comparison Model or Ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db05a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline is a binary performance case (True), ours is a continuous performance case (False)\n",
    "is_binary_performance = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae471c4",
   "metadata": {},
   "source": [
    "## Functions for Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9ce9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorting_key(filename: str) -> list:\n",
    "    # define a sorting key function using regular expressions\n",
    "    \n",
    "    # extract all numeric parts\n",
    "    parts = re.findall(r'\\d+', filename)\n",
    "    return [int(part) for part in parts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7f6610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_beta_distribution(axi: plt,\n",
    "                           distribution_object: TrustDistribution,\n",
    "                           trust_label: float,\n",
    "                           experiment_count: int,\n",
    "                           title_label_name: str,\n",
    "                           is_save_fig: bool = False) -> None:\n",
    "    \n",
    "    mean_value = distribution_object.get_beta_distribution_mean()\n",
    "    \n",
    "    label1 = \"Human Trust Model Histogram\"\n",
    "    label2 = \"Probability Density Function\"\n",
    "    label3 = \"Trust Estimation [Mean Value]\"\n",
    "    label4 = \"Trust Measurement [Co-Worker]\"\n",
    "    label5 = f\"Absolute Error (%) = {100 * abs(mean_value - trust_label):.1f}\"\n",
    "    \n",
    "    title_label = f\"(\\u03B1\\u2080={distribution_object.initial_alpha:.1f}; \\u03B2\\u2080={distribution_object.initial_beta:.1f}; \\u03B3={distribution_object.gamma:.4f}; \\u03B5={distribution_object.epsilon_reward:.4f}; \\u03C9\\u02E2={distribution_object.w_success:.4f}; \\u03C9\\u1da0={distribution_object.w_failure:.4f})\"\n",
    "    \n",
    "    # generate random samples from the beta distribution\n",
    "    sample_size = 2000\n",
    "    samples = stats.beta.rvs(distribution_object.alpha,\n",
    "                             distribution_object.beta,\n",
    "                             size=sample_size)\n",
    "\n",
    "    # plot the histogram of the generated samples\n",
    "    hist1 = axi.hist(samples,\n",
    "                     bins=30,\n",
    "                     density=True,\n",
    "                     alpha=0.5,\n",
    "                     color=\"darkorange\",\n",
    "                     label=label1)\n",
    "\n",
    "    # plot the probability density function (PDF) of the beta distribution\n",
    "    x = np.linspace(0, 1, 100)\n",
    "    pdf = stats.beta.pdf(x,\n",
    "                         distribution_object.alpha,\n",
    "                         distribution_object.beta)\n",
    "    plot1 = axi.plot(x,\n",
    "                     pdf,\n",
    "                     color=\"darkred\",\n",
    "                     linestyle=\"-\",\n",
    "                     linewidth=3,\n",
    "                     label=label2)\n",
    "\n",
    "    # plot the mean value as a horizontal line\n",
    "    line1 = axi.axvline(x=mean_value,\n",
    "                        color=\"darkgreen\",\n",
    "                        linestyle=\"--\",\n",
    "                        linewidth=3,\n",
    "                        label=label3)\n",
    "    \n",
    "    line2 = axi.axvline(x=trust_label,\n",
    "                        color=\"darkblue\",\n",
    "                        linestyle=\"--\",\n",
    "                        linewidth=2,\n",
    "                        label=label4)\n",
    "    \n",
    "    # check the proximity of mean_value and trust_label\n",
    "    if mean_value - trust_label < 0.04:\n",
    "\n",
    "        # if close, adjust the position of the text based on the sign of the difference\n",
    "        if mean_value > trust_label:\n",
    "            axi.text(mean_value + 0.008,\n",
    "                     0.4,\n",
    "                     f\"Estimation: % {100 * mean_value:.1f}\",\n",
    "                     color=\"darkgreen\",\n",
    "                     fontsize=16,\n",
    "                     fontweight=\"bold\",\n",
    "                     rotation=90,\n",
    "                     ha=\"left\")\n",
    "        else:\n",
    "            axi.text(mean_value - 0.004,\n",
    "                     0.4,\n",
    "                     f\"Estimation: % {100 * mean_value:.1f}\",\n",
    "                     color=\"darkgreen\",\n",
    "                     fontsize=16,\n",
    "                     fontweight=\"bold\",\n",
    "                     rotation=90,\n",
    "                     ha=\"right\")\n",
    "    else:\n",
    "        # adjust the position based on the sign of the difference\n",
    "        if mean_value > trust_label:\n",
    "            axi.text(mean_value - 0.006,\n",
    "                     0.4,\n",
    "                     f\"Estimation: % {100 * mean_value:.1f}\",\n",
    "                     color=\"darkgreen\",\n",
    "                     fontsize=16,\n",
    "                     fontweight=\"bold\",\n",
    "                     rotation=90,\n",
    "                     ha=\"right\")\n",
    "        else:\n",
    "            axi.text(mean_value + 0.03,\n",
    "                     0.4,\n",
    "                     f\"Estimation: % {100 * mean_value:.1f}\",\n",
    "                     color=\"darkgreen\",\n",
    "                     fontsize=16,\n",
    "                     fontweight=\"bold\",\n",
    "                     rotation=90,\n",
    "                     ha=\"left\")\n",
    "    \n",
    "    axi.text(trust_label - 0.04,\n",
    "             0.4,\n",
    "             f\"Measurement: % {100 * trust_label:.1f}\",\n",
    "             color=\"darkblue\",\n",
    "             fontsize=16,\n",
    "             fontweight=\"bold\",\n",
    "             rotation=90,\n",
    "             ha=\"left\")\n",
    "    \n",
    "    # create an arrow between mean_value and trust_label\n",
    "    arrow_params = {\n",
    "        \"arrowstyle\": \"<|-|>\",\n",
    "        \"mutation_scale\": 15,\n",
    "        \"color\": \"black\",\n",
    "        \"linewidth\": 2,\n",
    "        \"label\": label5\n",
    "    }\n",
    "    axi.annotate(\"\",\n",
    "                 xy=(mean_value, 0.07),\n",
    "                 xytext=(trust_label, 0.07),\n",
    "                 arrowprops=arrow_params)\n",
    "    arrow_legend = FancyArrowPatch((0, 0),\n",
    "                                   (1, 0),\n",
    "                                   **arrow_params)\n",
    "    \n",
    "    if mean_value <= 0.5:\n",
    "        anchor_posx, anchor_posy = 1.0, 1.0\n",
    "    else:\n",
    "        anchor_posx, anchor_posy = 0.65, 1.0\n",
    "    \n",
    "    legend = axi.legend(handles=[hist1[2][0], plot1[0], line1, line2, arrow_legend],\n",
    "                        labels=[label1, label2, label3, label4, label5],\n",
    "                        loc=\"upper right\",\n",
    "                        bbox_to_anchor=(anchor_posx, anchor_posy),\n",
    "                        fancybox=True,\n",
    "                        shadow=True,\n",
    "                        fontsize=14,\n",
    "                        title=f\"{title_label_name} Experiment {experiment_count}\",\n",
    "                        title_fontsize=\"12\")\n",
    "    legend.get_title().set_fontweight(\"bold\")\n",
    "\n",
    "    # format x-axis ticks as percentages\n",
    "    axi.get_xaxis().set_major_formatter(plt.FuncFormatter(lambda x, _: f'{100 * x:.0f}%'))\n",
    "    # set x-axis ticks at every 10 percent\n",
    "    axi.set_xticks(np.arange(0, 1.1, 0.1))\n",
    "    axi.tick_params(axis=\"x\",\n",
    "                    labelsize=14)\n",
    "    \n",
    "    axi.set_title(title_label,\n",
    "                  fontsize=14)\n",
    "    axi.set_xlabel(f\"Trust Estimation (%) - Beta Distribution (\\u03B1={distribution_object.alpha:.1f}; \\u03B2={distribution_object.beta:.1f})\",\n",
    "                   fontsize=15)\n",
    "    axi.set_ylabel(\"Probability Density Function (pdf)\",\n",
    "                   fontsize=15)\n",
    "    axi.grid(True,\n",
    "            which=\"both\",\n",
    "            axis=\"x\",\n",
    "            linestyle=\"--\",\n",
    "            color=\"grey\",\n",
    "            alpha=0.7,\n",
    "            linewidth=0.5)\n",
    "\n",
    "    if is_save_fig:\n",
    "        plt.savefig(f\"{title_label_name}_experiment_{experiment_count}_trust_distribution.png\",\n",
    "                    dpi=600,\n",
    "                    bbox_inches=\"tight\",\n",
    "                    transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f529cd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_through_trajectory(df: pd.DataFrame,\n",
    "                           column_names: list,\n",
    "                           distribution_object: TrustDistribution,\n",
    "                           optimization_object: MLEOptimization) -> Tuple[pd.DataFrame,\n",
    "                                                                          TrustDistribution]:\n",
    "    \n",
    "    # create a column to store estimated trust values; initialize it to zero as a default value\n",
    "    for column in column_names[:-1]:\n",
    "        df[column] = 0.0\n",
    "    \n",
    "    # create columns for quantile values to represent variance (%5 min and %95 )\n",
    "    df[\"TrustEstimationQ5\"] = 0.0\n",
    "    df[\"TrustEstimationQ95\"] = 0.0\n",
    "    \n",
    "    reward_array = df[\"Reward\"].to_numpy()\n",
    "    \n",
    "    # update distribution parameters (alpha and beta) with current success and failure weights\n",
    "    for idx, reward in enumerate(reward_array):\n",
    "        \n",
    "        # in binary model, the trust prediction distributino only gets updated after the experiment is finished\n",
    "        if is_binary_performance:\n",
    "            \n",
    "            # because the success or failure of the experiment could only be obtained after the scenario is finished,\n",
    "            # the update of reward function value will be laging from previous scenarios\n",
    "            if (idx + 1) != constants.TRAJECTORY_SIZE:\n",
    "                if idx == 0:\n",
    "                    distribution_object.update_parameters(performance=optimization_object.binary_performance_learning[-1])\n",
    "            \n",
    "            else:\n",
    "                distribution_object.update_parameters(performance=reward_array[idx - 1])\n",
    "        \n",
    "        else:\n",
    "            distribution_object.update_parameters(performance=reward)\n",
    "        \n",
    "        # store all important parameters in the dataframe\n",
    "        df.at[idx, column_names[0]] = distribution_object.alpha\n",
    "        df.at[idx, column_names[1]] = distribution_object.beta\n",
    "        df.at[idx, column_names[2]] = distribution_object.initial_alpha\n",
    "        df.at[idx, column_names[3]] = distribution_object.initial_beta\n",
    "        df.at[idx, column_names[4]] = distribution_object.w_success\n",
    "        df.at[idx, column_names[5]] = distribution_object.w_failure\n",
    "        df.at[idx, column_names[6]] = distribution_object.gamma\n",
    "        df.at[idx, column_names[7]] = distribution_object.epsilon_reward\n",
    "        \n",
    "        # calculate and store estimated trust value only after the reward is obtained\n",
    "        trust_estimation = distribution_object.get_beta_distribution_mean()\n",
    "        df.at[idx, column_names[8]] = trust_estimation\n",
    "        \n",
    "        # store %5 and %95 quantile values of the distribution\n",
    "        df.at[idx, \"TrustEstimationQ5\"] = distribution_object.distribution.ppf(0.05)\n",
    "        df.at[idx, \"TrustEstimationQ95\"] = distribution_object.distribution.ppf(0.95)\n",
    "    \n",
    "    return df, distribution_object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35670c92",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e505d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = functions.setup_config(device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e44e899",
   "metadata": {},
   "source": [
    "## Create Beta Distribution Object to Resembe Trust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d62ee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "trust_obj = TrustDistribution(initial_alpha=configs.initial_alpha,\n",
    "                              initial_beta=configs.initial_beta,\n",
    "                              initial_w_success=configs.initial_w_success,\n",
    "                              initial_w_failure=configs.initial_w_failure,\n",
    "                              gamma=configs.gamma,\n",
    "                              epsilon_reward=configs.epsilon_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79382873",
   "metadata": {},
   "source": [
    "## Read Robot Experiment Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfb88e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, results_path = functions.get_directories(parent_directory=parent_directory,\n",
    "                                            data_folder_name=\"\")\n",
    "experiments_folder_path = os.path.join(results_path,\n",
    "                                       \"experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c3fa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning trust behavior stage experiments and results\n",
    "learning_data_folder_path = os.path.join(experiments_folder_path,\n",
    "                                         constants.LEARNING_EXPERIMENT_FOLDER)\n",
    "if os.path.exists(learning_data_folder_path):\n",
    "    learning_excel_files = os.listdir(learning_data_folder_path)\n",
    "else:\n",
    "    print(\"NOTE: learning experiments are not saved @: \", learning_data_folder_path)\n",
    "\n",
    "# sort the file list using the custom sorting key\n",
    "learning_excel_files = sorted(learning_excel_files,\n",
    "                              key=sorting_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac793308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference stage experiments and results\n",
    "inference_data_folder_path = os.path.join(experiments_folder_path,\n",
    "                                          constants.INFERENCE_EXPERIMENT_FOLDER)\n",
    "if os.path.exists(inference_data_folder_path):\n",
    "    inference_excel_files = os.listdir(inference_data_folder_path)\n",
    "else:\n",
    "    print(\"NOTE: Inference experiments are not saved @: \", inference_data_folder_path)\n",
    "\n",
    "# sort the file list using the custom sorting key\n",
    "inference_excel_files = sorted(inference_excel_files,\n",
    "                               key=sorting_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654885b8",
   "metadata": {},
   "source": [
    "## Read Human Trust Measurement Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733ed165",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_trust_labels_list = []\n",
    "for learning_file_name in learning_excel_files:\n",
    "    trust_match = re.search(r\"trust_(\\d+)\",\n",
    "                            learning_file_name)\n",
    "    if trust_match:\n",
    "        learning_trust_labels_list.append(int(trust_match.group(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8411f803",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_trust_labels_list = []\n",
    "for inference_file_name in inference_excel_files:\n",
    "    trust_match = re.search(r\"trust_(\\d+)\",\n",
    "                            inference_file_name)\n",
    "    if trust_match:\n",
    "        inference_trust_labels_list.append(int(trust_match.group(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd5b396",
   "metadata": {},
   "source": [
    "## Define Constant Parameter List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc320b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Not Change Order\n",
    "prior_columns = [\"TimeStep\",\n",
    "                 \"StateNorm1\", \"StateNorm2\", \"StateNorm3\",\n",
    "                 \"Reward\"]\n",
    "column_names = [\"Alpha\", \"Beta\",\n",
    "                \"Alpha0\", \"Beta0\",\n",
    "                \"SuccessWeight\", \"FailureWeight\",\n",
    "                \"Gamma\", \"EpsilonReward\",\n",
    "                \"TrustEstimation\", \"TrustLabel\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5489e4ec",
   "metadata": {},
   "source": [
    "## Run Through Learning Trust Behavior Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26450606",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# in learning trust behavior, the following will be updated:\n",
    "# alpha, beta, alpha_0, beta_0, w_success, w_failure, gamma, eplison_reward\n",
    "learning_df = pd.DataFrame(columns=[\"Experiment\"] + prior_columns + column_names)\n",
    "\n",
    "initial_alpha = 0.5\n",
    "initial_beta = 0.5\n",
    "w_success = 0.2\n",
    "w_failure = 0.2\n",
    "gamma = 0.1\n",
    "epsilon_reward = 0.1\n",
    "\n",
    "for idx, learning_excel in enumerate(learning_excel_files):\n",
    "    \n",
    "    learn_df = pd.read_excel(os.path.join(learning_data_folder_path,\n",
    "                                          learning_excel))\n",
    "    \n",
    "    # measured trust value of the particular experiment (measured at the end of the experiment)\n",
    "    trust_label = learning_trust_labels_list[idx]\n",
    "    true_trust = trust_label / 100 # from percentage to range [0, 1]\n",
    "    \n",
    "    # store measured trust\n",
    "    learn_df[column_names[9]] = true_trust\n",
    "    \n",
    "    # save referring index of the experiment\n",
    "    learn_df[\"Experiment\"] = idx + 1\n",
    "    \n",
    "    # collect all dataframes for validation\n",
    "    if len(learning_df) == 0: learning_df = learn_df\n",
    "    else: learning_df = pd.concat([learning_df, learn_df], axis=0, ignore_index=True)\n",
    "    del learn_df\n",
    "    \n",
    "    # optimization object for maximum likelihood estimation (MLE)\n",
    "    mle_obj = MLEOptimization(learning_experiment_data=learning_df,\n",
    "                              is_binary_performance=is_binary_performance,\n",
    "                              seed=constants.RANDOM_SEED)\n",
    "    \n",
    "    if is_binary_performance:\n",
    "        # run optimization (binary)\n",
    "        trust_obj, initial_alpha, initial_beta, w_success, w_failure = mle_obj.fit([initial_alpha,\n",
    "                                                                                    initial_beta,\n",
    "                                                                                    w_success,\n",
    "                                                                                    w_failure])\n",
    "    else:\n",
    "        # run optimization (proposed)\n",
    "        trust_obj, initial_alpha, initial_beta, w_success, w_failure, gamma, epsilon_reward = mle_obj.fit([initial_alpha,\n",
    "                                                                                                           initial_beta,\n",
    "                                                                                                           w_success,\n",
    "                                                                                                           w_failure,\n",
    "                                                                                                           gamma,\n",
    "                                                                                                           epsilon_reward])\n",
    "\n",
    "    # store important data related to the plotting of the distribution\n",
    "    learning_df.loc[learning_df[\"Experiment\"] == idx + 1, column_names[0]] = trust_obj.alpha\n",
    "    learning_df.loc[learning_df[\"Experiment\"] == idx + 1, column_names[1]] = trust_obj.beta\n",
    "    learning_df.loc[learning_df[\"Experiment\"] == idx + 1, column_names[2]] = trust_obj.initial_alpha\n",
    "    learning_df.loc[learning_df[\"Experiment\"] == idx + 1, column_names[3]] = trust_obj.initial_beta\n",
    "    learning_df.loc[learning_df[\"Experiment\"] == idx + 1, column_names[4]] = trust_obj.w_success\n",
    "    learning_df.loc[learning_df[\"Experiment\"] == idx + 1, column_names[5]] = trust_obj.w_failure\n",
    "    \n",
    "    if not is_binary_performance:\n",
    "        learning_df.loc[learning_df[\"Experiment\"] == idx + 1, column_names[6]] = trust_obj.gamma\n",
    "        learning_df.loc[learning_df[\"Experiment\"] == idx + 1, column_names[7]] = trust_obj.epsilon_reward\n",
    "    \n",
    "    # update reward function value to binary case when binary comparison model is selected\n",
    "    if is_binary_performance:\n",
    "        learning_df.loc[learning_df[\"Experiment\"] == idx + 1, prior_columns[4]] = mle_obj.reward_binary\n",
    "    \n",
    "    # plot estimation, label, error in the trust distribution\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "    plot_beta_distribution(axi=ax,\n",
    "                           distribution_object=trust_obj,\n",
    "                           trust_label=true_trust,\n",
    "                           experiment_count=idx + 1,\n",
    "                           title_label_name=\"Learning Trust Behavior\",\n",
    "                           is_save_fig=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe240d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learning_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c65d971",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_binary_performance:\n",
    "    saving_file_name_1 = \"learning_stage_experiment_results_binary.xlsx\"\n",
    "else:\n",
    "    saving_file_name_1 = \"learning_stage_experiment_results.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c811cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_df.to_excel(saving_file_name_1,\n",
    "                     index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea912b17",
   "metadata": {},
   "source": [
    "## Plotting Distributions on One Plot All Together for Trust Learning Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5422aca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_df = pd.read_excel(saving_file_name_1)\n",
    "\n",
    "alphas = learning_df[column_names[0]].tolist()\n",
    "betas = learning_df[column_names[1]].tolist()\n",
    "true_trusts = learning_df[column_names[9]].tolist()\n",
    "experiment_ids = learning_df[\"Experiment\"].tolist()\n",
    "\n",
    "last_alpha = None\n",
    "last_beta = None\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "unique_experiments = sorted(set(experiment_ids))\n",
    "colors = plt.cm.inferno(np.linspace(0, 1, len(unique_experiments)))\n",
    "discrete_cmap = ListedColormap(colors)\n",
    "norm = Normalize(vmin=min(unique_experiments), vmax=max(unique_experiments))\n",
    "sm = ScalarMappable(cmap=discrete_cmap, norm=norm)\n",
    "\n",
    "for idx in range(len(alphas)):\n",
    "    \n",
    "    if alphas[idx] != last_alpha:\n",
    "        \n",
    "        last_alpha = alphas[idx]\n",
    "        last_beta = betas[idx]\n",
    "        \n",
    "        trust_obj.alpha = last_alpha\n",
    "        trust_obj.beta = last_beta\n",
    "        \n",
    "        mean_value = trust_obj.get_beta_distribution_mean()\n",
    "        sample_size = 2000\n",
    "        samples = stats.beta.rvs(trust_obj.alpha, trust_obj.beta, size=sample_size)\n",
    "        \n",
    "        color = discrete_cmap(norm(experiment_ids[idx]))\n",
    "        \n",
    "        ax.hist(samples, bins=30, density=True, alpha=0.15, color=color)\n",
    "        \n",
    "        x = np.linspace(0, 1, 100)\n",
    "        pdf = stats.beta.pdf(x, trust_obj.alpha, trust_obj.beta)\n",
    "        ax.plot(x, pdf, color=color, linestyle=\"-\", linewidth=4)\n",
    "\n",
    "cbar = plt.colorbar(sm, ax=ax, orientation=\"vertical\", fraction=0.03, pad=0.04)\n",
    "cbar.ax.set_visible(True)\n",
    "cbar.set_label(\"Stage 3 Experiments Number [#]\", fontsize=22)\n",
    "cbar.ax.tick_params(labelsize=16)\n",
    "cbar.set_ticks(unique_experiments)\n",
    "cbar.set_ticklabels([str(exp) for exp in unique_experiments])\n",
    "cbar.ax.set_position([0.05, 0.1, 0.03, 0.75])\n",
    "\n",
    "ax.get_xaxis().set_major_formatter(plt.FuncFormatter(lambda x, _: f'{100 * x:.0f}%'))\n",
    "ax.set_xticks(np.arange(0, 1.1, 0.1))\n",
    "ax.tick_params(axis=\"x\", labelsize=18)\n",
    "ax.tick_params(axis=\"y\", labelsize=16)\n",
    "\n",
    "# ax.set_title(\"Learning Trust Behavior Stage Experiment Trust Estimations\", fontsize=20)\n",
    "ax.set_xlabel(\"Human Trust Estimation (%)\", fontsize=24)\n",
    "ax.set_ylabel(\"Probability Density Function (pdf)\", fontsize=22)\n",
    "ax.grid(True, which=\"both\", axis=\"x\", linestyle=\"--\", color=\"grey\", alpha=0.7, linewidth=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"learning_stage_experiment_trust_distributions.png\", dpi=600, bbox_inches=\"tight\", transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3eb7149",
   "metadata": {},
   "source": [
    "## Learning Trust Behavior Stage Trust Measurements vs. Reward Function Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c77925",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_stage_experiment_idxs = np.unique(learning_df[\"Experiment\"].to_numpy())\n",
    "\n",
    "learning_stage_trust_labels_df = learning_df[[\"TimeStep\", \"TrustLabel\"]]\n",
    "learning_stage_trust_labels = learning_stage_trust_labels_df[\n",
    "    learning_stage_trust_labels_df[\"TimeStep\"] == constants.TRAJECTORY_SIZE][\"TrustLabel\"]\n",
    "\n",
    "learning_stage_rewards_df = learning_df[[\"Experiment\", \"Reward\"]]\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "bar_width = 0.6\n",
    "bar_positions = np.unique(learning_df[\"Experiment\"].to_numpy()) - (1.4 * bar_width)\n",
    "\n",
    "learning_stage_exp_idxs = range(0, len(learning_stage_experiment_idxs))\n",
    "\n",
    "bars = ax1.bar(bar_positions,\n",
    "               learning_stage_trust_labels,\n",
    "               width=bar_width,\n",
    "               color=\"#4682B4\",\n",
    "               edgecolor=\"navy\",\n",
    "               linewidth=1.5,\n",
    "               label=\"Human Trust Measurement\")\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height() * 100\n",
    "    \n",
    "    ax1.text(bar.get_x() + bar.get_width() / 2.0, -0.065,\n",
    "             f\"{height:.0f}%\",\n",
    "             ha=\"center\",\n",
    "             va=\"bottom\",\n",
    "             color=\"navy\",\n",
    "             fontsize=18)\n",
    "\n",
    "sns.violinplot(x=\"Experiment\",\n",
    "               y=\"Reward\",\n",
    "               data=learning_stage_rewards_df, ax=ax2,\n",
    "               palette=\"inferno\",\n",
    "               alpha=0.1,\n",
    "               scale=\"width\",\n",
    "               width=0.6)\n",
    "\n",
    "ax1.set_xticks(learning_stage_exp_idxs)\n",
    "ax1.set_xticklabels(range(1, 11))\n",
    "ax2.set_xticks(learning_stage_exp_idxs)\n",
    "ax2.set_xticklabels(range(1, 11))\n",
    "\n",
    "ax1.set_xlim(-0.5, 10)\n",
    "ax1.set_ylim(-0.07, 0.95)\n",
    "ax1.get_yaxis().set_major_formatter(plt.FuncFormatter(lambda x, _: f'{100 * x:.0f}%'))\n",
    "ax2.set_yticks(np.arange(-0.2, 0.65, 0.1))\n",
    "\n",
    "ax1.set_yticks(np.arange(0, 1.0, 0.1))\n",
    "\n",
    "ax1.tick_params(axis=\"x\", labelcolor=\"black\", labelsize=20)\n",
    "ax1.tick_params(axis=\"y\", labelcolor=\"navy\", labelsize=20)\n",
    "ax2.tick_params(axis=\"y\", labelcolor=\"black\", labelsize=20)\n",
    "\n",
    "ax1.set_xlabel(\"Stage 3 Experiments Number [#]\", color=\"black\", fontsize=24)\n",
    "ax1.set_ylabel(\"Human Trust Measurement (%)\", color=\"navy\", fontsize=24)\n",
    "ax2.set_ylabel(\"Reward Function Output (rᵩ*)\", color=\"black\", fontsize=24)\n",
    "\n",
    "ax2.grid(True, which=\"both\", axis=\"y\", linestyle=\"--\", color=\"grey\", alpha=0.7, linewidth=0.8, zorder=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"learning_stage_experiment_trust_reward_scales.png\", dpi=600, bbox_inches=\"tight\", transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5139d142",
   "metadata": {},
   "source": [
    "## Run Through Inference Experiments After Tuning Beta Distribution Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9294bee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# in learning trust behavior, the following will be constant:\n",
    "# alpha_0, beta_0, w_success, w_failure, gamma, epsilon_reward\n",
    "INFERENCE_df = pd.DataFrame(columns=[\"Experiment\"] + prior_columns + column_names)\n",
    "\n",
    "for idx, inference_excel in enumerate(inference_excel_files):\n",
    "    inference_df = pd.read_excel(os.path.join(inference_data_folder_path,\n",
    "                                              inference_excel))\n",
    "    \n",
    "    # measured trust value of the particular experiment (measured at the end of the experiment)\n",
    "    trust_label = inference_trust_labels_list[idx]\n",
    "    true_trust = trust_label / 100 # from percentage to range [0, 1]\n",
    "    \n",
    "    # store measured trust\n",
    "    inference_df[column_names[9]] = true_trust\n",
    "    \n",
    "    # save referring index of the experiment\n",
    "    inference_df[\"Experiment\"] = idx + 1\n",
    "    \n",
    "    # in binary model case, update reward function values\n",
    "    if is_binary_performance:\n",
    "        inference_df[\"Reward\"] = mle_obj.binary_performance_inference[idx]\n",
    "    \n",
    "    # by running the following, only alpha and beta parameters will be updated\n",
    "    inference_df, trust_obj = run_through_trajectory(df=inference_df,\n",
    "                                                     column_names=column_names,\n",
    "                                                     distribution_object=trust_obj,\n",
    "                                                     optimization_object=mle_obj)\n",
    "    \n",
    "    # collect all dataframes\n",
    "    if len(inference_df) == 0:\n",
    "        INFERENCE_df = inference_df\n",
    "    else:\n",
    "        INFERENCE_df = pd.concat([INFERENCE_df, inference_df], axis=0, ignore_index=True)\n",
    "    \n",
    "    # plot estimation, label, error in the trust distribution\n",
    "    fig, ax = plt.subplots(1, 1,\n",
    "                           figsize=(8, 5))\n",
    "    plot_beta_distribution(axi=ax,\n",
    "                           distribution_object=trust_obj,\n",
    "                           trust_label=true_trust,\n",
    "                           experiment_count=idx + 1,\n",
    "                           title_label_name=\"Inference Stage\",\n",
    "                           is_save_fig=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d6cfed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "INFERENCE_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74b611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_binary_performance:\n",
    "    saving_file_name_2 = \"inference_stage_experiment_results_binary.xlsx\"\n",
    "else:\n",
    "    saving_file_name_2 = \"inference_stage_experiment_results.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540512a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFERENCE_df.to_excel(saving_file_name_2,\n",
    "                      index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f8d7d0",
   "metadata": {},
   "source": [
    "## Trust Distribution Shifts in One Scenario (PDF and CDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f260ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inference_df = INFERENCE_df[INFERENCE_df[\"Experiment\"] == 2]\n",
    "\n",
    "alphas = inference_df[column_names[0]].tolist()\n",
    "betas = inference_df[column_names[1]].tolist()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = plt.cm.inferno(np.linspace(0, 1, len(alphas)))\n",
    "discrete_cmap = ListedColormap(colors)\n",
    "norm = Normalize(vmin=0, vmax=len(alphas))\n",
    "sm = ScalarMappable(cmap=discrete_cmap, norm=norm)\n",
    "\n",
    "for idx in range(len(alphas)):\n",
    "    \n",
    "    trust_obj.alpha = alphas[idx]\n",
    "    trust_obj.beta = betas[idx]\n",
    "\n",
    "    mean_value = trust_obj.get_beta_distribution_mean()\n",
    "    sample_size = 2000\n",
    "    samples = stats.beta.rvs(trust_obj.alpha, trust_obj.beta, size=sample_size)\n",
    "\n",
    "    color = discrete_cmap(norm(idx + 1))\n",
    "\n",
    "    ax.hist(samples, bins=30, density=True, alpha=0.2, color=color)\n",
    "\n",
    "    x = np.linspace(0, 0.5, 50)\n",
    "    pdf = stats.beta.pdf(x, trust_obj.alpha, trust_obj.beta)\n",
    "    ax.plot(x, pdf, color=color, linestyle=\"-\", linewidth=4)\n",
    "\n",
    "cbar = plt.colorbar(sm, ax=ax, orientation=\"vertical\", fraction=0.03, pad=0.04)\n",
    "cbar.ax.set_visible(True)\n",
    "cbar.set_label(\"Timestep (Step Number) [#]\", fontsize=24)\n",
    "cbar.ax.tick_params(labelsize=16)\n",
    "cbar.set_ticks(range(len(alphas)))\n",
    "cbar.set_ticklabels([str(exp + 1) for exp in range(len(alphas))])\n",
    "# cbar.ax.set_position([0.05, 0.2, 0.03, 7])\n",
    "\n",
    "ax.get_xaxis().set_major_formatter(plt.FuncFormatter(lambda x, _: f'{100 * x:.0f}%'))\n",
    "ax.set_xticks(np.arange(0, 0.51, 0.1))\n",
    "ax.tick_params(axis=\"x\", labelsize=18)\n",
    "ax.tick_params(axis=\"y\", labelsize=16)\n",
    "\n",
    "ax.set_xlabel(\"Human Trust Estimation (%)\", fontsize=24)\n",
    "ax.set_ylabel(\"Probability Density Function (pdf)\", fontsize=22)\n",
    "ax.grid(True, which=\"both\", axis=\"x\", linestyle=\"--\", color=\"grey\", alpha=0.7, linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"inference_stage_experiment_trust_distribution_one_scenario.png\", dpi=600, bbox_inches=\"tight\", transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1950c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = inference_df[column_names[0]].tolist()\n",
    "betas = inference_df[column_names[1]].tolist()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = plt.cm.inferno(np.linspace(0, 1, len(alphas)))\n",
    "discrete_cmap = ListedColormap(colors)\n",
    "norm = Normalize(vmin=0, vmax=len(alphas))\n",
    "sm = ScalarMappable(cmap=discrete_cmap, norm=norm)\n",
    "\n",
    "for idx in range(len(alphas)):\n",
    "    \n",
    "    trust_obj.alpha = alphas[idx]\n",
    "    trust_obj.beta = betas[idx]\n",
    "\n",
    "    sample_size = 2000\n",
    "    samples = stats.beta.rvs(trust_obj.alpha, trust_obj.beta, size=sample_size)\n",
    "\n",
    "    color = discrete_cmap(norm(idx + 1))\n",
    "\n",
    "#     ax.hist(samples, bins=30, density=True, alpha=0.2, color=color)\n",
    "\n",
    "    x = np.linspace(0, 0.5, 50)\n",
    "    cdf = stats.beta.cdf(x, trust_obj.alpha, trust_obj.beta)\n",
    "    ax.plot(x, cdf, color=color, linestyle=\"-\", linewidth=3)\n",
    "\n",
    "cbar = plt.colorbar(sm, ax=ax, orientation=\"vertical\", fraction=0.03, pad=0.04)\n",
    "cbar.ax.set_visible(True)\n",
    "cbar.set_label(\"Timestep (Step Number) [#]\", fontsize=24)\n",
    "cbar.ax.tick_params(labelsize=16)\n",
    "cbar.set_ticks(range(len(alphas)))\n",
    "cbar.set_ticklabels([str(exp + 1) for exp in range(len(alphas))])\n",
    "\n",
    "ax.get_xaxis().set_major_formatter(plt.FuncFormatter(lambda x, _: f'{100 * x:.0f}%'))\n",
    "ax.set_xticks(np.arange(0, 0.51, 0.1))\n",
    "ax.tick_params(axis=\"x\", labelsize=18)\n",
    "ax.tick_params(axis=\"y\", labelsize=16)\n",
    "\n",
    "ax.set_xlabel(\"Human Trust Estimation (%)\", fontsize=24)\n",
    "ax.set_ylabel(\"Cumulative Distribution Function (CDF)\", fontsize=20)\n",
    "ax.grid(True, which=\"both\", axis=\"x\", linestyle=\"--\", color=\"grey\", alpha=0.7, linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"inference_stage_experiment_trust_distribution_cdf_scenario.png\", dpi=600, bbox_inches=\"tight\", transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700485d4",
   "metadata": {},
   "source": [
    "## Visualize Trajectory of Inference Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c33fc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_experiment_number = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979ff488",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df = INFERENCE_df[INFERENCE_df[\"Experiment\"] == inference_experiment_number]\n",
    "\n",
    "state_norms = [constants.MAX_DISTANCE_TO_OBJECT,\n",
    "               constants.MAX_DISTANCE_TO_TARGET,\n",
    "               constants.MAX_DISTANCE_TO_GROUND]\n",
    "\n",
    "normalized_states = inference_df[[\"StateNorm1\",\n",
    "                                  \"StateNorm2\",\n",
    "                                  \"StateNorm3\"]].to_numpy()\n",
    "\n",
    "denormalized_states = common.denormalize_state(state_norm=normalized_states,\n",
    "                                               norm_value_list=state_norms)\n",
    "# correcting extra length addition on end-effector\n",
    "denormalized_states[:, 1:3] = denormalized_states[:, 1:3] - constants.ROBOT_BASE_HEIGHT\n",
    "\n",
    "time_steps = inference_df[\"TimeStep\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd6ccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "plt.plot(time_steps, denormalized_states[:, 0],\n",
    "         linestyle=\"--\",\n",
    "         linewidth=5,\n",
    "         color=\"darkred\",\n",
    "         label=\"Distance to Obstacle\")\n",
    "plt.plot(time_steps, denormalized_states[:, 1] + 0.1, # add correction to target (m)\n",
    "         linestyle=\":\",\n",
    "         linewidth=5,\n",
    "         color=\"darkgreen\",\n",
    "         label=\"Distance to Target Position\")\n",
    "plt.plot(time_steps, denormalized_states[:, 2],\n",
    "         linestyle=\"-\",\n",
    "         linewidth=5,\n",
    "         color=\"darkblue\",\n",
    "         label=\"Distance to Ground Level\")\n",
    "\n",
    "plt.xticks(np.arange(1, max(time_steps) + 1, 1), fontsize=20)\n",
    "plt.yticks(np.arange(0.0, 2.4, 0.2), fontsize=20)\n",
    "\n",
    "ax.grid(True, which=\"both\", axis=\"y\", linestyle=\"--\", color=\"grey\", alpha=0.8, linewidth=0.8)\n",
    "\n",
    "plt.title(f\"Inference Experiment {inference_experiment_number} - Robot Trajectory Execution\", fontsize=25)\n",
    "plt.xlabel(\"Timestep (Step Number) [#]\", fontsize=26)\n",
    "plt.ylabel(\"Robot State Vector [meters]\", fontsize=26)\n",
    "\n",
    "plt.legend(fancybox=True, shadow=True, loc=\"upper right\", fontsize=22)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(f\"inference_stage_experiment_{inference_experiment_number}_robot_state.png\",\n",
    "#             dpi=600, bbox_inches=\"tight\", transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e1a650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
